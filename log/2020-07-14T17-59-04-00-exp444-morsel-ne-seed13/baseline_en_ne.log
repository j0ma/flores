================ FLORES BASELINE WITH CLIP_NORM=0.1, BPE=5000 AND SEED=13 USING MORSEL ================
About to train the supervised for the following language pair: EN-NE
CHECKPOINT_DIR is set to './checkpoints/2020-07-14T17-59-04-00-exp444-morsel-ne-seed13/checkpoints_en_ne'
Creating checkpoint directory if it doesn't exist...
Data folder is: data-bin/wiki_ne_en_morsel/
Beginning training...
Time at beginning: Tue Jul 14 23:13:59 EDT 2020
Namespace(activation_dropout=0.2, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, arch='transformer', attention_dropout=0.2, best_checkpoint_metric='loss', bpe=None, bucket_cap_mb=25, clip_norm=0.1, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/wiki_ne_en_morsel/', dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=2, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=5, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.4, empty_cache_freq=0, encoder_attention_heads=2, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=5, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=True, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.2, layer_wise_attention=False, layernorm_embedding=False, lazy_load=False, left_pad_source='True', left_pad_target='False', load_alignments=False, log_format=None, log_interval=1000, lr=[0.001], lr_scheduler='inverse_sqrt', max_epoch=100, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=4000, max_tokens_valid=4000, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=1e-09, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_token_positional_embeddings=False, num_workers=1, optimizer='adam', optimizer_overrides='{}', raw_text=False, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/2020-07-14T17-59-04-00-exp444-morsel-ne-seed13/checkpoints_en_ne', save_interval=10, save_interval_updates=0, seed=13, sentence_avg=False, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang='en', target_lang='ne', task='translation', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, train_subset='train', truncate_source=False, update_freq=[4], upsample_primary=1, use_bmuf=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0001)
| [en] dictionary: 3960 types
| [ne] dictionary: 3960 types
| loaded 2559 examples from: data-bin/wiki_ne_en_morsel/valid.ne-en.en
| loaded 2559 examples from: data-bin/wiki_ne_en_morsel/valid.ne-en.ne
| data-bin/wiki_ne_en_morsel/ valid en-ne 2559 examples
TransformerModel(
  (encoder): TransformerEncoder(
    (embed_tokens): Embedding(3960, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(3960, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
)
| model transformer, criterion LabelSmoothedCrossEntropyCriterion
| num. model params: 38811648 (num. trained: 38811648)
| training on 1 GPUs
| max tokens per GPU = 4000 and max sentences per GPU = None
| no existing checkpoint found ./checkpoints/2020-07-14T17-59-04-00-exp444-morsel-ne-seed13/checkpoints_en_ne/checkpoint_last.pt
| loading train data for epoch 0
| loaded 563947 examples from: data-bin/wiki_ne_en_morsel/train.ne-en.en
| loaded 563947 examples from: data-bin/wiki_ne_en_morsel/train.ne-en.ne
| data-bin/wiki_ne_en_morsel/ train en-ne 563947 examples
| WARNING: 5 samples have invalid sizes and will be skipped, max_positions=(1024, 1024), first few sample ids=[553289, 513531, 486736, 304187, 478247]
| WARNING: overflow detected, setting loss scale to: 64.0
| WARNING: overflow detected, setting loss scale to: 32.0
| WARNING: overflow detected, setting loss scale to: 16.0
| epoch 001 | loss 9.353 | nll_loss 8.307 | ppl 316.69 | wps 44071 | ups 3 | wpb 13862.907 | bsz 753.824 | num_updates 740 | lr 0.000185081 | gnorm 0.777 | clip 1.000 | oom 0.000 | loss_scale 16.000 | wall 239 | train_wall 192
| epoch 001 | valid on 'valid' subset | loss 10.402 | nll_loss 9.408 | ppl 679.54 | num_updates 740
| epoch 002 | loss 7.176 | nll_loss 5.417 | ppl 42.74 | wps 46058 | ups 3 | wpb 13865.153 | bsz 759.007 | num_updates 1483 | lr 0.000370813 | gnorm 0.505 | clip 1.000 | oom 0.000 | loss_scale 16.000 | wall 464 | train_wall 376
| epoch 002 | valid on 'valid' subset | loss 10.096 | nll_loss 8.972 | ppl 502.07 | num_updates 1483
| epoch 003 | loss 6.424 | nll_loss 4.435 | ppl 21.64 | wps 46315 | ups 3 | wpb 13865.153 | bsz 759.007 | num_updates 2226 | lr 0.000556544 | gnorm 0.436 | clip 1.000 | oom 0.000 | loss_scale 16.000 | wall 688 | train_wall 559
| epoch 003 | valid on 'valid' subset | loss 9.859 | nll_loss 8.664 | ppl 405.59 | num_updates 2226
| epoch 004 | loss 6.020 | nll_loss 3.913 | ppl 15.07 | wps 47456 | ups 3 | wpb 13865.153 | bsz 759.007 | num_updates 2969 | lr 0.000742276 | gnorm 0.386 | clip 1.000 | oom 0.000 | loss_scale 16.000 | wall 906 | train_wall 739
| epoch 004 | valid on 'valid' subset | loss 9.657 | nll_loss 8.399 | ppl 337.49 | num_updates 2969
| epoch 005 | loss 5.770 | nll_loss 3.592 | ppl 12.06 | wps 46278 | ups 3 | wpb 13865.153 | bsz 759.007 | num_updates 3712 | lr 0.000928007 | gnorm 0.348 | clip 1.000 | oom 0.000 | loss_scale 16.000 | wall 1130 | train_wall 923
| epoch 005 | valid on 'valid' subset | loss 9.518 | nll_loss 8.219 | ppl 297.88 | num_updates 3712
| WARNING: overflow detected, setting loss scale to: 16.0
| epoch 006 | loss 5.601 | nll_loss 3.377 | ppl 10.39 | wps 46590 | ups 3 | wpb 13863.538 | bsz 757.032 | num_updates 4454 | lr 0.000947665 | gnorm 0.314 | clip 1.000 | oom 0.000 | loss_scale 16.000 | wall 1352 | train_wall 1105
| epoch 006 | valid on 'valid' subset | loss 9.460 | nll_loss 8.132 | ppl 280.6 | num_updates 4454
| epoch 007 | loss 5.436 | nll_loss 3.168 | ppl 8.99 | wps 50383 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 5197 | lr 0.000877311 | gnorm 0.279 | clip 1.000 | oom 0.000 | loss_scale 16.000 | wall 1558 | train_wall 1273
| epoch 007 | valid on 'valid' subset | loss 9.378 | nll_loss 8.009 | ppl 257.69 | num_updates 5197
| epoch 008 | loss 5.315 | nll_loss 3.015 | ppl 8.08 | wps 50272 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 5940 | lr 0.00082061 | gnorm 0.261 | clip 1.000 | oom 0.000 | loss_scale 16.000 | wall 1764 | train_wall 1443
| epoch 008 | valid on 'valid' subset | loss 9.267 | nll_loss 7.857 | ppl 231.78 | num_updates 5940
| epoch 009 | loss 5.225 | nll_loss 2.901 | ppl 7.47 | wps 51603 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 6683 | lr 0.00077365 | gnorm 0.248 | clip 1.000 | oom 0.000 | loss_scale 16.000 | wall 1964 | train_wall 1609
| epoch 009 | valid on 'valid' subset | loss 9.189 | nll_loss 7.768 | ppl 217.9 | num_updates 6683
| epoch 010 | loss 5.155 | nll_loss 2.812 | ppl 7.02 | wps 52536 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 7426 | lr 0.000733926 | gnorm 0.241 | clip 1.000 | oom 0.000 | loss_scale 16.000 | wall 2161 | train_wall 1772
| epoch 010 | valid on 'valid' subset | loss 9.201 | nll_loss 7.752 | ppl 215.61 | num_updates 7426
| saved checkpoint ./checkpoints/2020-07-14T17-59-04-00-exp444-morsel-ne-seed13/checkpoints_en_ne/checkpoint10.pt (epoch 10 @ 7426 updates) (writing took 0.8128418922424316 seconds)
| epoch 011 | loss 5.097 | nll_loss 2.738 | ppl 6.67 | wps 52195 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 8169 | lr 0.000699754 | gnorm 0.233 | clip 1.000 | oom 0.000 | loss_scale 16.000 | wall 2360 | train_wall 1937
| epoch 011 | valid on 'valid' subset | loss 9.219 | nll_loss 7.763 | ppl 217.24 | num_updates 8169 | best_loss 9.20135
| epoch 012 | loss 5.049 | nll_loss 2.678 | ppl 6.4 | wps 53914 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 8912 | lr 0.00066995 | gnorm 0.229 | clip 1.000 | oom 0.000 | loss_scale 32.000 | wall 2552 | train_wall 2098
| epoch 012 | valid on 'valid' subset | loss 9.132 | nll_loss 7.681 | ppl 205.26 | num_updates 8912 | best_loss 9.13182
| epoch 013 | loss 5.009 | nll_loss 2.627 | ppl 6.18 | wps 54880 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 9655 | lr 0.000643656 | gnorm 0.225 | clip 1.000 | oom 0.000 | loss_scale 32.000 | wall 2741 | train_wall 2256
| epoch 013 | valid on 'valid' subset | loss 9.073 | nll_loss 7.589 | ppl 192.5 | num_updates 9655 | best_loss 9.07275
| epoch 014 | loss 4.974 | nll_loss 2.582 | ppl 5.99 | wps 54506 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 10398 | lr 0.000620233 | gnorm 0.222 | clip 1.000 | oom 0.000 | loss_scale 32.000 | wall 2931 | train_wall 2414
| epoch 014 | valid on 'valid' subset | loss 9.050 | nll_loss 7.586 | ppl 192.14 | num_updates 10398 | best_loss 9.04986
| epoch 015 | loss 4.943 | nll_loss 2.543 | ppl 5.83 | wps 55565 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 11141 | lr 0.000599195 | gnorm 0.219 | clip 1.000 | oom 0.000 | loss_scale 32.000 | wall 3117 | train_wall 2569
| epoch 015 | valid on 'valid' subset | loss 9.035 | nll_loss 7.554 | ppl 187.89 | num_updates 11141 | best_loss 9.03537
| epoch 016 | loss 4.916 | nll_loss 2.510 | ppl 5.69 | wps 55404 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 11884 | lr 0.000580161 | gnorm 0.219 | clip 1.000 | oom 0.000 | loss_scale 32.000 | wall 3304 | train_wall 2726
| epoch 016 | valid on 'valid' subset | loss 9.015 | nll_loss 7.531 | ppl 184.93 | num_updates 11884 | best_loss 9.0147
| WARNING: overflow detected, setting loss scale to: 32.0
| epoch 017 | loss 4.891 | nll_loss 2.478 | ppl 5.57 | wps 55087 | ups 4 | wpb 13866.136 | bsz 759.695 | num_updates 12626 | lr 0.000562856 | gnorm 0.216 | clip 1.000 | oom 0.000 | loss_scale 32.000 | wall 3491 | train_wall 2883
| epoch 017 | valid on 'valid' subset | loss 9.034 | nll_loss 7.565 | ppl 189.39 | num_updates 12626 | best_loss 9.03415
| epoch 018 | loss 4.870 | nll_loss 2.451 | ppl 5.47 | wps 53779 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 13369 | lr 0.000546991 | gnorm 0.215 | clip 1.000 | oom 0.000 | loss_scale 32.000 | wall 3684 | train_wall 3042
| epoch 018 | valid on 'valid' subset | loss 9.023 | nll_loss 7.529 | ppl 184.71 | num_updates 13369 | best_loss 9.02266
| epoch 019 | loss 4.850 | nll_loss 2.426 | ppl 5.37 | wps 50880 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 14112 | lr 0.000532397 | gnorm 0.213 | clip 1.000 | oom 0.000 | loss_scale 32.000 | wall 3887 | train_wall 3210
| epoch 019 | valid on 'valid' subset | loss 9.022 | nll_loss 7.521 | ppl 183.74 | num_updates 14112 | best_loss 9.02182
| epoch 020 | loss 4.831 | nll_loss 2.402 | ppl 5.29 | wps 50960 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 14855 | lr 0.000518912 | gnorm 0.213 | clip 1.000 | oom 0.000 | loss_scale 32.000 | wall 4090 | train_wall 3376
| epoch 020 | valid on 'valid' subset | loss 8.994 | nll_loss 7.473 | ppl 177.69 | num_updates 14855 | best_loss 8.99359
| saved checkpoint ./checkpoints/2020-07-14T17-59-04-00-exp444-morsel-ne-seed13/checkpoints_en_ne/checkpoint20.pt (epoch 20 @ 14855 updates) (writing took 1.2521731853485107 seconds)
| epoch 021 | loss 4.816 | nll_loss 2.383 | ppl 5.21 | wps 50617 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 15598 | lr 0.000506402 | gnorm 0.213 | clip 1.000 | oom 0.000 | loss_scale 32.000 | wall 4296 | train_wall 3545
| epoch 021 | valid on 'valid' subset | loss 8.994 | nll_loss 7.489 | ppl 179.59 | num_updates 15598 | best_loss 8.99355
| epoch 022 | loss 4.800 | nll_loss 2.363 | ppl 5.14 | wps 50111 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 16341 | lr 0.000494756 | gnorm 0.212 | clip 1.000 | oom 0.000 | loss_scale 32.000 | wall 4503 | train_wall 3715
| epoch 022 | valid on 'valid' subset | loss 8.991 | nll_loss 7.480 | ppl 178.56 | num_updates 16341 | best_loss 8.99089
| WARNING: overflow detected, setting loss scale to: 32.0
| epoch 023 | loss 4.785 | nll_loss 2.345 | ppl 5.08 | wps 50517 | ups 4 | wpb 13863.811 | bsz 758.682 | num_updates 17083 | lr 0.000483891 | gnorm 0.210 | clip 1.000 | oom 0.000 | loss_scale 32.000 | wall 4707 | train_wall 3883
| epoch 023 | valid on 'valid' subset | loss 9.012 | nll_loss 7.520 | ppl 183.53 | num_updates 17083 | best_loss 8.99359
| epoch 024 | loss 4.772 | nll_loss 2.328 | ppl 5.02 | wps 51246 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 17826 | lr 0.0004737 | gnorm 0.212 | clip 1.000 | oom 0.000 | loss_scale 32.000 | wall 4909 | train_wall 4050
| epoch 024 | valid on 'valid' subset | loss 9.026 | nll_loss 7.533 | ppl 185.24 | num_updates 17826 | best_loss 8.99359
| epoch 025 | loss 4.760 | nll_loss 2.312 | ppl 4.97 | wps 50555 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 18569 | lr 0.000464126 | gnorm 0.211 | clip 1.000 | oom 0.000 | loss_scale 32.000 | wall 5114 | train_wall 4219
| epoch 025 | valid on 'valid' subset | loss 8.931 | nll_loss 7.411 | ppl 170.21 | num_updates 18569 | best_loss 8.93102
| epoch 026 | loss 4.748 | nll_loss 2.297 | ppl 4.91 | wps 50808 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 19312 | lr 0.00045511 | gnorm 0.210 | clip 1.000 | oom 0.000 | loss_scale 32.000 | wall 5318 | train_wall 4386
| epoch 026 | valid on 'valid' subset | loss 8.940 | nll_loss 7.427 | ppl 172.03 | num_updates 19312 | best_loss 8.93958
| epoch 027 | loss 4.737 | nll_loss 2.284 | ppl 4.87 | wps 50726 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 20055 | lr 0.0004466 | gnorm 0.210 | clip 1.000 | oom 0.000 | loss_scale 32.000 | wall 5522 | train_wall 4555
| epoch 027 | valid on 'valid' subset | loss 8.956 | nll_loss 7.435 | ppl 173.07 | num_updates 20055 | best_loss 8.95587
| epoch 028 | loss 4.727 | nll_loss 2.270 | ppl 4.82 | wps 50421 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 20798 | lr 0.00043855 | gnorm 0.211 | clip 1.000 | oom 0.000 | loss_scale 32.000 | wall 5727 | train_wall 4724
| epoch 028 | valid on 'valid' subset | loss 8.915 | nll_loss 7.399 | ppl 168.81 | num_updates 20798 | best_loss 8.91454
| epoch 029 | loss 4.717 | nll_loss 2.259 | ppl 4.79 | wps 50625 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 21541 | lr 0.00043092 | gnorm 0.209 | clip 1.000 | oom 0.000 | loss_scale 64.000 | wall 5932 | train_wall 4892
| epoch 029 | valid on 'valid' subset | loss 8.958 | nll_loss 7.448 | ppl 174.66 | num_updates 21541 | best_loss 8.95782
| epoch 030 | loss 4.708 | nll_loss 2.247 | ppl 4.75 | wps 50322 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 22284 | lr 0.000423676 | gnorm 0.209 | clip 1.000 | oom 0.000 | loss_scale 64.000 | wall 6137 | train_wall 5061
| epoch 030 | valid on 'valid' subset | loss 8.960 | nll_loss 7.448 | ppl 174.61 | num_updates 22284 | best_loss 8.96001
| saved checkpoint ./checkpoints/2020-07-14T17-59-04-00-exp444-morsel-ne-seed13/checkpoints_en_ne/checkpoint30.pt (epoch 30 @ 22284 updates) (writing took 1.2556126117706299 seconds)
| epoch 031 | loss 4.699 | nll_loss 2.236 | ppl 4.71 | wps 50417 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 23027 | lr 0.000416784 | gnorm 0.209 | clip 1.000 | oom 0.000 | loss_scale 64.000 | wall 6344 | train_wall 5230
| epoch 031 | valid on 'valid' subset | loss 8.932 | nll_loss 7.435 | ppl 173.07 | num_updates 23027 | best_loss 8.93182
| WARNING: overflow detected, setting loss scale to: 32.0
| epoch 032 | loss 4.691 | nll_loss 2.226 | ppl 4.68 | wps 49044 | ups 4 | wpb 13867.674 | bsz 756.989 | num_updates 23769 | lr 0.000410227 | gnorm 0.209 | clip 1.000 | oom 0.000 | loss_scale 32.000 | wall 6555 | train_wall 5403
| epoch 032 | valid on 'valid' subset | loss 8.994 | nll_loss 7.492 | ppl 180.02 | num_updates 23769 | best_loss 8.96001
| epoch 033 | loss 4.683 | nll_loss 2.215 | ppl 4.64 | wps 50686 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 24512 | lr 0.000403962 | gnorm 0.210 | clip 1.000 | oom 0.000 | loss_scale 32.000 | wall 6759 | train_wall 5572
| epoch 033 | valid on 'valid' subset | loss 8.942 | nll_loss 7.418 | ppl 171.01 | num_updates 24512 | best_loss 8.94204
| epoch 034 | loss 4.675 | nll_loss 2.205 | ppl 4.61 | wps 50535 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 25255 | lr 0.000397975 | gnorm 0.209 | clip 1.000 | oom 0.000 | loss_scale 32.000 | wall 6964 | train_wall 5741
| epoch 034 | valid on 'valid' subset | loss 8.947 | nll_loss 7.439 | ppl 173.58 | num_updates 25255 | best_loss 8.94714
| epoch 035 | loss 4.668 | nll_loss 2.196 | ppl 4.58 | wps 50722 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 25998 | lr 0.000392247 | gnorm 0.209 | clip 1.000 | oom 0.000 | loss_scale 32.000 | wall 7168 | train_wall 5908
| epoch 035 | valid on 'valid' subset | loss 8.912 | nll_loss 7.392 | ppl 168 | num_updates 25998 | best_loss 8.91153
| epoch 036 | loss 4.661 | nll_loss 2.187 | ppl 4.55 | wps 50270 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 26741 | lr 0.00038676 | gnorm 0.209 | clip 1.000 | oom 0.000 | loss_scale 32.000 | wall 7374 | train_wall 6077
| epoch 036 | valid on 'valid' subset | loss 8.926 | nll_loss 7.404 | ppl 169.41 | num_updates 26741 | best_loss 8.92557
| epoch 037 | loss 4.655 | nll_loss 2.180 | ppl 4.53 | wps 52107 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 27484 | lr 0.000381496 | gnorm 0.209 | clip 1.000 | oom 0.000 | loss_scale 32.000 | wall 7573 | train_wall 6241
| epoch 037 | valid on 'valid' subset | loss 8.953 | nll_loss 7.443 | ppl 173.97 | num_updates 27484 | best_loss 8.95276
| epoch 038 | loss 4.648 | nll_loss 2.172 | ppl 4.5 | wps 53155 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 28227 | lr 0.000376442 | gnorm 0.209 | clip 1.000 | oom 0.000 | loss_scale 64.000 | wall 7768 | train_wall 6403
| epoch 038 | valid on 'valid' subset | loss 8.877 | nll_loss 7.347 | ppl 162.75 | num_updates 28227 | best_loss 8.87747
| WARNING: overflow detected, setting loss scale to: 32.0
| epoch 039 | loss 4.642 | nll_loss 2.164 | ppl 4.48 | wps 53463 | ups 4 | wpb 13867.891 | bsz 757.377 | num_updates 28969 | lr 0.000371589 | gnorm 0.209 | clip 1.000 | oom 0.000 | loss_scale 32.000 | wall 7961 | train_wall 6564
| epoch 039 | valid on 'valid' subset | loss 8.890 | nll_loss 7.367 | ppl 165.09 | num_updates 28969 | best_loss 8.88989
| epoch 040 | loss 4.636 | nll_loss 2.157 | ppl 4.46 | wps 53195 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 29712 | lr 0.000366914 | gnorm 0.209 | clip 1.000 | oom 0.000 | loss_scale 32.000 | wall 8156 | train_wall 6726
| epoch 040 | valid on 'valid' subset | loss 8.907 | nll_loss 7.385 | ppl 167.1 | num_updates 29712 | best_loss 8.90669
| saved checkpoint ./checkpoints/2020-07-14T17-59-04-00-exp444-morsel-ne-seed13/checkpoints_en_ne/checkpoint40.pt (epoch 40 @ 29712 updates) (writing took 1.1491317749023438 seconds)
| epoch 041 | loss 4.631 | nll_loss 2.150 | ppl 4.44 | wps 53728 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 30455 | lr 0.00036241 | gnorm 0.210 | clip 1.000 | oom 0.000 | loss_scale 32.000 | wall 8350 | train_wall 6887
| epoch 041 | valid on 'valid' subset | loss 8.913 | nll_loss 7.391 | ppl 167.89 | num_updates 30455 | best_loss 8.90669
| epoch 042 | loss 4.625 | nll_loss 2.142 | ppl 4.41 | wps 54179 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 31198 | lr 0.000358069 | gnorm 0.210 | clip 1.000 | oom 0.000 | loss_scale 32.000 | wall 8541 | train_wall 7047
| epoch 042 | valid on 'valid' subset | loss 8.951 | nll_loss 7.441 | ppl 173.74 | num_updates 31198 | best_loss 8.90669
| WARNING: overflow detected, setting loss scale to: 16.0
| epoch 043 | loss 4.620 | nll_loss 2.136 | ppl 4.4 | wps 54623 | ups 4 | wpb 13864.220 | bsz 759.189 | num_updates 31940 | lr 0.000353885 | gnorm 0.210 | clip 1.000 | oom 0.000 | loss_scale 16.000 | wall 8730 | train_wall 7205
| epoch 043 | valid on 'valid' subset | loss 8.907 | nll_loss 7.377 | ppl 166.25 | num_updates 31940 | best_loss 8.90669
| epoch 044 | loss 4.615 | nll_loss 2.130 | ppl 4.38 | wps 55353 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 32683 | lr 0.00034984 | gnorm 0.211 | clip 1.000 | oom 0.000 | loss_scale 16.000 | wall 8917 | train_wall 7362
| epoch 044 | valid on 'valid' subset | loss 8.891 | nll_loss 7.361 | ppl 164.36 | num_updates 32683 | best_loss 8.89056
| epoch 045 | loss 4.611 | nll_loss 2.124 | ppl 4.36 | wps 55631 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 33426 | lr 0.00034593 | gnorm 0.212 | clip 1.000 | oom 0.000 | loss_scale 16.000 | wall 9103 | train_wall 7518
| epoch 045 | valid on 'valid' subset | loss 8.906 | nll_loss 7.379 | ppl 166.43 | num_updates 33426 | best_loss 8.90611
| epoch 046 | loss 4.605 | nll_loss 2.117 | ppl 4.34 | wps 55178 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 34169 | lr 0.000342148 | gnorm 0.212 | clip 1.000 | oom 0.000 | loss_scale 16.000 | wall 9290 | train_wall 7675
| epoch 046 | valid on 'valid' subset | loss 8.909 | nll_loss 7.393 | ppl 168.09 | num_updates 34169 | best_loss 8.90669
| epoch 047 | loss 4.600 | nll_loss 2.111 | ppl 4.32 | wps 55424 | ups 4 | wpb 13865.153 | bsz 759.007 | num_updates 34912 | lr 0.000338487 | gnorm 0.212 | clip 1.000 | oom 0.000 | loss_scale 16.000 | wall 9477 | train_wall 7832
| epoch 047 | valid on 'valid' subset | loss 8.918 | nll_loss 7.385 | ppl 167.2 | num_updates 34912 | best_loss 8.90669
