================ FLORES BASELINE REPRODUCTION SCRIPT WITH FP16 TRAINING + LARGEBATCH + LR 5e-3 + CLIP_NORM 0.1 ================
About to train the supervised for the following language pair: EN-NE
Checkpoint directory unset! Setting to default value...
CHECKPOINT_DIR is set to './checkpoints/2020-03-12T22-45-04-00/checkpoints_en_ne'
Creating checkpoint directory if it doesn't exist...
Data folder is: data-bin/wiki_ne_en_bpe5000/
Beginning training...
Time at beginning: Thu Mar 12 22:57:03 EDT 2020
Namespace(activation_dropout=0.2, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, arch='transformer', attention_dropout=0.2, best_checkpoint_metric='loss', bpe=None, bucket_cap_mb=25, clip_norm=0.1, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/wiki_ne_en_bpe5000/', dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=2, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=5, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.4, empty_cache_freq=0, encoder_attention_heads=2, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=5, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=True, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.2, layer_wise_attention=False, layernorm_embedding=False, lazy_load=False, left_pad_source='True', left_pad_target='False', load_alignments=False, log_format=None, log_interval=1000, lr=[0.005], lr_scheduler='inverse_sqrt', max_epoch=100, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=16000, max_tokens_valid=16000, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=1e-09, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_token_positional_embeddings=False, num_workers=1, optimizer='adam', optimizer_overrides='{}', raw_text=False, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='./checkpoints/2020-03-12T22-45-04-00/checkpoints_en_ne', save_interval=10, save_interval_updates=0, seed=1, sentence_avg=False, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang='en', target_lang='ne', task='translation', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0001)
| [en] dictionary: 5000 types
| [ne] dictionary: 5000 types
| loaded 2559 examples from: data-bin/wiki_ne_en_bpe5000/valid.ne-en.en
| loaded 2559 examples from: data-bin/wiki_ne_en_bpe5000/valid.ne-en.ne
| data-bin/wiki_ne_en_bpe5000/ valid en-ne 2559 examples
TransformerModel(
  (encoder): TransformerEncoder(
    (embed_tokens): Embedding(5000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embed_tokens): Embedding(5000, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (self_attn): MultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
)
| model transformer, criterion LabelSmoothedCrossEntropyCriterion
| num. model params: 39344128 (num. trained: 39344128)
| training on 1 GPUs
| max tokens per GPU = 16000 and max sentences per GPU = None
| no existing checkpoint found ./checkpoints/2020-03-12T22-45-04-00/checkpoints_en_ne/checkpoint_last.pt
| loading train data for epoch 0
| loaded 563779 examples from: data-bin/wiki_ne_en_bpe5000/train.ne-en.en
| loaded 563779 examples from: data-bin/wiki_ne_en_bpe5000/train.ne-en.ne
| data-bin/wiki_ne_en_bpe5000/ train en-ne 563779 examples
| WARNING: overflow detected, setting loss scale to: 64.0
| WARNING: overflow detected, setting loss scale to: 32.0
| WARNING: overflow detected, setting loss scale to: 16.0
| WARNING: overflow detected, setting loss scale to: 8.0
| WARNING: overflow detected, setting loss scale to: 4.0
| WARNING: overflow detected, setting loss scale to: 2.0
| epoch 001 | loss 10.133 | nll_loss 9.237 | ppl 603.38 | wps 79805 | ups 7 | wpb 11827.601 | bsz 872.790 | num_updates 632 | lr 0.000790084 | gnorm 1.283 | clip 1.000 | oom 0.000 | loss_scale 2.000 | wall 99 | train_wall 91
| epoch 001 | valid on 'valid' subset | loss 9.503 | nll_loss 8.216 | ppl 297.31 | num_updates 632
| epoch 002 | loss 8.348 | nll_loss 6.851 | ppl 115.45 | wps 80447 | ups 7 | wpb 11829.412 | bsz 883.666 | num_updates 1270 | lr 0.00158757 | gnorm 0.760 | clip 1.000 | oom 0.000 | loss_scale 2.000 | wall 193 | train_wall 182
| epoch 002 | valid on 'valid' subset | loss 9.150 | nll_loss 7.710 | ppl 209.35 | num_updates 1270
| epoch 003 | loss 7.846 | nll_loss 6.197 | ppl 73.35 | wps 80662 | ups 7 | wpb 11829.412 | bsz 883.666 | num_updates 1908 | lr 0.00238505 | gnorm 0.964 | clip 1.000 | oom 0.000 | loss_scale 2.000 | wall 288 | train_wall 274
| epoch 003 | valid on 'valid' subset | loss 8.989 | nll_loss 7.503 | ppl 181.42 | num_updates 1908
| WARNING: overflow detected, setting loss scale to: 1.0
| WARNING: overflow detected, setting loss scale to: 0.5
| epoch 004 | loss 7.647 | nll_loss 5.939 | ppl 61.37 | wps 80284 | ups 7 | wpb 11831.821 | bsz 881.313 | num_updates 2544 | lr 0.00318004 | gnorm 1.333 | clip 1.000 | oom 0.000 | loss_scale 0.500 | wall 382 | train_wall 365
| epoch 004 | valid on 'valid' subset | loss 9.051 | nll_loss 7.584 | ppl 191.82 | num_updates 2544
| WARNING: overflow detected, setting loss scale to: 0.25
| WARNING: overflow detected, setting loss scale to: 0.125
| WARNING: overflow detected, setting loss scale to: 0.0625
| epoch 005 | loss 7.460 | nll_loss 5.697 | ppl 51.88 | wps 80402 | ups 7 | wpb 11826.439 | bsz 886.682 | num_updates 3179 | lr 0.00397377 | gnorm 1.280 | clip 1.000 | oom 0.000 | loss_scale 0.062 | wall 476 | train_wall 456
| epoch 005 | valid on 'valid' subset | loss 8.982 | nll_loss 7.462 | ppl 176.36 | num_updates 3179
| WARNING: overflow detected, setting loss scale to: 0.03125
| epoch 006 | loss 7.366 | nll_loss 5.575 | ppl 47.68 | wps 80801 | ups 7 | wpb 11827.170 | bsz 884.551 | num_updates 3816 | lr 0.00477 | gnorm 1.485 | clip 1.000 | oom 0.000 | loss_scale 0.031 | wall 570 | train_wall 547
| epoch 006 | valid on 'valid' subset | loss 9.065 | nll_loss 7.552 | ppl 187.66 | num_updates 3816
| epoch 007 | loss 7.242 | nll_loss 5.414 | ppl 42.65 | wps 80917 | ups 7 | wpb 11829.412 | bsz 883.666 | num_updates 4454 | lr 0.00473833 | gnorm 2.170 | clip 1.000 | oom 0.000 | loss_scale 0.031 | wall 664 | train_wall 638
| epoch 007 | valid on 'valid' subset | loss 8.986 | nll_loss 7.436 | ppl 173.11 | num_updates 4454
| WARNING: overflow detected, setting loss scale to: 0.015625
| epoch 008 | loss 7.094 | nll_loss 5.219 | ppl 37.24 | wps 80828 | ups 7 | wpb 11825.446 | bsz 884.714 | num_updates 5091 | lr 0.00443199 | gnorm 1.363 | clip 1.000 | oom 0.000 | loss_scale 0.016 | wall 757 | train_wall 729
| epoch 008 | valid on 'valid' subset | loss 8.870 | nll_loss 7.310 | ppl 158.67 | num_updates 5091
| WARNING: overflow detected, setting loss scale to: 0.0078125
| WARNING: overflow detected, setting loss scale to: 0.00390625
| WARNING: overflow detected, setting loss scale to: 0.001953125
| WARNING: overflow detected, setting loss scale to: 0.0009765625
| epoch 009 | loss 6.988 | nll_loss 5.076 | ppl 33.73 | wps 80330 | ups 7 | wpb 11833.617 | bsz 877.254 | num_updates 5725 | lr 0.00417938 | gnorm 2.059 | clip 1.000 | oom 0.000 | loss_scale 0.001 | wall 852 | train_wall 820
| epoch 009 | valid on 'valid' subset | loss 8.780 | nll_loss 7.223 | ppl 149.38 | num_updates 5725
| WARNING: overflow detected, setting loss scale to: 0.00048828125
| WARNING: overflow detected, setting loss scale to: 0.000244140625
| WARNING: overflow detected, setting loss scale to: 0.0001220703125
Done training.
Time at end: Thu Mar 12 23:11:22 EDT 2020
